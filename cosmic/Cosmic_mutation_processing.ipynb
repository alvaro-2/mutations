{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "from collections import defaultdict\n",
    "\n",
    "llpsprots = \"../../llps_human_all_proteins.csv\"\n",
    "datafile  = \"../../cosmic/CosmicMutantExport.tsv.gz\"\n",
    "\n",
    "mapfile_ENSP = \"../llps_uniprot2ENSP.tab.txt\"\n",
    "mapfile_ENST = \"../llps_uniprot2ENST.tab.txt\"\n",
    "\n",
    "def load_mapping(mapfile):\n",
    "    mapdict = defaultdict(lambda: False)\n",
    "    with open(mapfile) as infmt:\n",
    "        next(infmt)\n",
    "        for line in infmt:\n",
    "            arr = line.strip().split(\"\\t\")\n",
    "            if mapdict[arr[1]]:\n",
    "                print(f\"WARNING: {arr[1]} already in dict\")\n",
    "            else:\n",
    "                mapdict[arr[1]] = True\n",
    "    return mapdict\n",
    "                \n",
    "ENSP_dict = load_mapping(mapfile_ENSP)\n",
    "ENST_dict = load_mapping(mapfile_ENST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read COSMIC file line by line, to heavy to load entirely in memory\n",
    "\n",
    "import gzip\n",
    "\n",
    "select = [\"Gene name\", \"Accession Number\", \"HGNC ID\", \"Primary site\", \n",
    "          \"Primary histology\", \"Genome-wide screen\", \"GENOMIC_MUTATION_ID\", \"LEGACY_MUTATION_ID\",\n",
    "          \"MUTATION_ID\", \"Mutation CDS\", \"Mutation AA\", \"Mutation Description\", \"GRCh\", \n",
    "          \"Mutation genome position\", \"SNP\", \"Mutation somatic status\", \"Pubmed_PMID\", \"Age\",\n",
    "          \"HGVSP\", \"HGVSC\", \"HGVSG\"]\n",
    "\n",
    "all_cols = list()\n",
    "with gzip.open(datafile) as ifile, open(\"COSMIC_crop.txt\", 'w') as ofile:\n",
    "    headers = next(ifile).decode().rstrip('\\n').split(\"\\t\")\n",
    "    ix = [headers.index(x) for x in select]\n",
    "    ofile.write(\"\\t\".join(select)+\"\\n\")\n",
    "    for i,line in enumerate(ifile):\n",
    "        try:\n",
    "            arr = line.decode().rstrip(\"\\n\").split(\"\\t\")\n",
    "\n",
    "            cols = [arr[i] for i in ix]\n",
    "            # print(cols[18], cols[19], cols[20])\n",
    "            if cols[18] != \"p.?\" and cols[18] != \"\":\n",
    "                ENSP_id = cols[18].split(\".\")[0]\n",
    "            if cols[19] != \"\":\n",
    "                ENST_id = cols[19].split(\".\")[0]\n",
    "\n",
    "            # Filter only mutations in our LLPS dataset\n",
    "            if ENSP_dict[ENSP_id] or ENST_dict[ENST_id]:\n",
    "                ofile.write(\"\\t\".join(cols)+\"\\n\")        \n",
    "        except:\n",
    "            print(f\"Error at line {i}: {line}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "mut_dict = defaultdict(list)\n",
    "\n",
    "with open(\"COSMIC_crop.txt\") as ifile:\n",
    "    headers = next(ifile)\n",
    "    for line in ifile:\n",
    "        arr = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        mut_dict[arr[11]].append(arr)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in mut_dict:\n",
    "    print(f\"{k}: {len(mut_dict[k])} mutations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "import numpy as np\n",
    "\n",
    "headers = [\"Gene name\", \"Accession Number\", \"HGNC ID\", \"Primary site\", \n",
    "          \"Primary histology\", \"Genome-wide screen\", \"GENOMIC_MUTATION_ID\", \"LEGACY_MUTATION_ID\",\n",
    "          \"MUTATION_ID\", \"Mutation CDS\", \"Mutation AA\", \"Mutation Description\", \"GRCh\", \n",
    "          \"Mutation genome position\", \"SNP\", \"Mutation somatic status\", \"Pubmed_PMID\", \"Age\",\n",
    "          \"HGVSP\", \"HGVSC\", \"HGVSG\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_en_cols(df, column, conseq, conseq_regex, override=False):\n",
    "    '''\n",
    "    recibe un DataFrame, el nombre de una columna auxiliar (column)\n",
    "    y un string con el tipo de consecuencia (conseq). La col. auxiliar\n",
    "    es una tupla con los elementos implicados en una mutacion\n",
    "    como la siguiente (aa1, start_pos, aa2, end_pos, aa/s_nuevos).\n",
    "    Devuelve el DataFrame df con estas 5 nuevas columnas\n",
    "    '''\n",
    "    \n",
    "    df_crop = df[df[column].str.contains(conseq_regex)].copy()\n",
    "      \n",
    "    if override:\n",
    "        df_crop['aux'] = df_crop[column].str.findall(conseq_regex).str[0]\n",
    "    else:\n",
    "        df_crop['aux'] = df_crop[column].str.findall('^([A-Z][a-z]{2})(\\d+)_?([A-Z][a-z]{2})?(\\d+)?'+conseq_regex+'(.*)$').str[0]\n",
    "        \n",
    "    if conseq == \"missense\" or conseq == \"nonsense\":\n",
    "        df_crop['start_aa'] = df_crop['aux'].map(lambda x: x[1])\n",
    "        df_crop['end_aa'] = df_crop['start_aa']\n",
    "        df_crop['from'] = df_crop['aux'].map(lambda x: x[0])        \n",
    "        df_crop['to'] = df_crop['aux'].map(lambda x: x[2])\n",
    "    else:\n",
    "    \n",
    "        # start position\n",
    "        df_crop['start_aa'] = df_crop['aux'].map(lambda x: x[1])\n",
    "\n",
    "        # end position\n",
    "        df_crop['end_aa'] = df_crop['aux'].map(lambda x: int(x[3]) if x[3] != '' else np.nan)\n",
    "\n",
    "        # from: es el/los aa que cambian\n",
    "        df_crop['from'] = df_crop['aux'].map(lambda x: x[0] + x[2]) # concateno si existe mas de un aa que cambia (o sea, si es un rango)\n",
    "\n",
    "        # to: aa/s nuevos\n",
    "        if conseq == \"nonsense\":\n",
    "            df_crop['to'] = \"Ter\"\n",
    "        elif conseq == \"deletion\":\n",
    "            df_crop['to'] = \"\"\n",
    "        else:\n",
    "            df_crop['to'] = df_crop['aux'].map(lambda x: x[4] if x[4] != '' else np.nan)\n",
    "\n",
    "    # consecuencia de la mutacion\n",
    "    df_crop['consequence'] = conseq\n",
    "\n",
    "    df_crop = df_crop.drop(columns=['aux'])\n",
    "\n",
    "    return df_crop[['cambio', 'start_aa', 'end_aa', 'from', 'to', 'consequence']]\n",
    "\n",
    "def seq3(seq):\n",
    "    \n",
    "    protein_letters_1to3 = {\n",
    "        \"A\": \"Ala\",\n",
    "        \"C\": \"Cys\",\n",
    "        \"D\": \"Asp\",\n",
    "        \"E\": \"Glu\",\n",
    "        \"F\": \"Phe\",\n",
    "        \"G\": \"Gly\",\n",
    "        \"H\": \"His\",\n",
    "        \"I\": \"Ile\",\n",
    "        \"K\": \"Lys\",\n",
    "        \"L\": \"Leu\",\n",
    "        \"M\": \"Met\",\n",
    "        \"N\": \"Asn\",\n",
    "        \"P\": \"Pro\",\n",
    "        \"Q\": \"Gln\",\n",
    "        \"R\": \"Arg\",\n",
    "        \"S\": \"Ser\",\n",
    "        \"T\": \"Thr\",\n",
    "        \"V\": \"Val\",\n",
    "        \"W\": \"Trp\",\n",
    "        \"Y\": \"Tyr\",\n",
    "        \"B\": \"Asx\",\n",
    "        \"X\": \"Xaa\",\n",
    "        \"Z\": \"Glx\",\n",
    "        \"J\": \"Xle\",\n",
    "        \"U\": \"Sec\",\n",
    "        \"O\": \"Pyl\",\n",
    "        \"*\": \"Ter\"\n",
    "    }\n",
    "    \n",
    "    return \"\".join(protein_letters_1to3.get(aa, \"Xaa\") for aa in seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def separar_en_cols_missense(df, column, conseq, conseq_regex, override=False):\n",
    "    \n",
    "    df_crop = df[df[column].str.contains(conseq_regex)].copy()\n",
    "      \n",
    "    if override:\n",
    "        df_crop['aux'] = df_crop[column].str.findall(conseq_regex).str[0]\n",
    "    else:\n",
    "        df_crop['aux'] = df_crop[column].str.findall('^([A-Z][a-z]{2})(\\d+)_?([A-Z][a-z]{2})?(\\d+)?'+conseq_regex+'(.*)$').str[0]\n",
    "            \n",
    "    # start position\n",
    "    df_crop['start_aa'] = df_crop['aux'].map(lambda x: x[1])\n",
    "    df_crop.start_aa = df_crop.start_aa.apply(int)\n",
    "    \n",
    "    # end position\n",
    "    df_crop['end_aa'] = df_crop['start_aa']\n",
    "    # df_crop['end_aa'] = df_crop['aux'].map(lambda x: int(x[1]) if x[1] != '' else np.nan)\n",
    "    \n",
    "    # from: es el/los aa que cambian\n",
    "    df_crop['from'] = df_crop['aux'].map(lambda x: seq3(x[0])) # concateno si existe mas de un aa que cambia (o sea, si es un rango)\n",
    "    df_crop['from'] = df_crop['from'].apply(str)\n",
    "    \n",
    "    df_crop['to'] = df_crop['aux'].map(lambda x: seq3(x[2]))\n",
    "    df_crop['to'] = df_crop['to'].apply(str)\n",
    "        \n",
    "    # consecuencia de la mutacion\n",
    "    df_crop['consequence'] = conseq\n",
    "\n",
    "    df_crop = df_crop.drop(columns=['aux'])\n",
    "\n",
    "    return df_crop[['cambio', 'start_aa', 'end_aa', 'from', 'to', 'consequence']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process MISSENSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tmp = pd.DataFrame(mut_dict[\"Substitution - Missense\"], columns=headers)\n",
    "\n",
    "# Subset mutations with \"p.\" only\n",
    "df_tmp['cambio'] = df_tmp[\"HGVSP\"].map(lambda x: re.findall('p\\..*$', x))\n",
    "df_tmp['cambio'] = df_tmp.cambio.str[0]\n",
    "df_tmp.cambio = df_tmp.cambio.str.lstrip('p.') \n",
    "\n",
    "# separate those that don't have HGVSP\n",
    "ix_nulls = df_tmp[\"cambio\"].isnull()\n",
    "df_nulls = df_tmp[ix_nulls].copy()\n",
    "\n",
    "# do classic missense processing\n",
    "missense = separar_en_cols(df_tmp[~ix_nulls], \"cambio\", \"missense\", '^([A-Z][a-z]{2})(\\d+)(?!Ter)([A-Z][a-z]{2})$', override=True)\n",
    "df_tmp = df_tmp.drop(columns=[\"cambio\"])\n",
    "\n",
    "# Now process those that have NULL in HGVSP but have some information on \"Mutation AA\"\n",
    "# small check in case something is not a missense mutation\n",
    "check = df_nulls[\"Mutation AA\"].map(lambda x: re.findall('p\\.[A-Z]\\d+[A-Z]$', x))\n",
    "if np.sum(check.isnull()) > 0:\n",
    "    print(\"Warning MISSENSE! some nulls or errors here\")\n",
    "\n",
    "# continue with mutation processing\n",
    "ix_X = df_nulls[\"Mutation AA\"].str.contains('p\\.[A-Z]\\d+X$')  # discard mutations to X\n",
    "df_pass = df_nulls[~ix_X].copy()\n",
    "df_pass[\"cambio\"] = df_pass[\"Mutation AA\"].str.lstrip('p.')\n",
    "df_done = separar_en_cols_missense(df_pass, \"cambio\", \"missense\", '^([A-Z])(\\d+)([A-Z])$', override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_missense = pd.concat((missense, df_done))\n",
    "missense_df = pd.merge(df_tmp, all_missense, right_index=True, left_index=True)\n",
    "print(missense.shape)\n",
    "print(df_done.shape)\n",
    "print(all_missense.shape)\n",
    "print(missense_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missense_df.to_csv(\"llps_missense_cosmic.csv.gz\", sep=\",\", header=True, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del missense_df\n",
    "del all_missense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process NONSENSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process Nonsense\n",
    "\n",
    "df_tmp = pd.DataFrame(mut_dict[\"Substitution - Nonsense\"], columns=headers)\n",
    "\n",
    "# Subset mutations with \"p.\" only\n",
    "df_tmp['cambio'] = df_tmp[\"HGVSP\"].map(lambda x: re.findall('p\\..*$', x))\n",
    "df_tmp['cambio'] = df_tmp.cambio.str[0]\n",
    "df_tmp.cambio = df_tmp.cambio.str.lstrip('p.') \n",
    "\n",
    "# # separate those that don't have HGVSP\n",
    "ix_nulls = df_tmp[\"cambio\"].isnull()\n",
    "df_nulls = df_tmp[ix_nulls].copy()\n",
    "\n",
    "# # do classic missense processing\n",
    "nonsense = separar_en_cols(df_tmp[~ix_nulls], \"cambio\", \"nonsense\", \"(?<=\\d)Ter\", override=False)\n",
    "df_tmp = df_tmp.drop(columns=[\"cambio\"])\n",
    "\n",
    "# # Now process those that have NULL in HGVSP but have some information on \"Mutation AA\"\n",
    "# # small check in case something is not a missense mutation\n",
    "check = df_nulls[\"Mutation AA\"].map(lambda x: re.findall('p\\.[A-Z]\\d+\\*$', x))\n",
    "if np.sum(check.isnull()) > 0:\n",
    "    print(\"Warning NONSENSE! some nulls or errors here\")\n",
    "\n",
    "# # continue with mutation processing\n",
    "df_nulls[\"cambio\"] = df_nulls[\"Mutation AA\"].str.lstrip('p.')\n",
    "df_done = separar_en_cols_missense(df_nulls, \"cambio\", \"nonsense\", '^([A-Z])(\\d+)(\\*)$', override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nonsense.shape)\n",
    "print(df_done.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nonsense = pd.concat((nonsense, df_done))\n",
    "nonsense_df = pd.merge(df_tmp, all_nonsense, right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonsense_df.to_csv(\"llps_nonsense_cosmic.csv.gz\", sep=\",\", header=True, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nonsense_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del nonsense_df\n",
    "del all_nonsense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process DELETIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Process Deletions\n",
    "\n",
    "df_tmp = pd.DataFrame(mut_dict[\"Deletion - In frame\"], columns=headers)\n",
    "df_tmp\n",
    "\n",
    "# Subset mutations with \"p.\" only\n",
    "df_tmp['cambio'] = df_tmp[\"HGVSP\"].map(lambda x: re.findall('p\\..*$', x))\n",
    "df_tmp['cambio'] = df_tmp.cambio.str[0]\n",
    "df_tmp.cambio = df_tmp.cambio.str.lstrip('p.') \n",
    "\n",
    "# separate those that don't have HGVSP\n",
    "ix_nulls = df_tmp[\"cambio\"].isnull()\n",
    "df_nulls = df_tmp[ix_nulls]\n",
    "df_notnulls = df_tmp[~ix_nulls].copy()\n",
    "ix_right = df_notnulls[\"cambio\"].str.contains('^([A-Z][a-z]{2})(\\d+)_?([A-Z][a-z]{2})?(\\d+)?del$')\n",
    "df_weird = df_notnulls[~ix_right].copy()\n",
    "\n",
    "# # # do classic missense processing\n",
    "deletions = separar_en_cols(df_notnulls[ix_right], \"cambio\", \"deletion\", '^([A-Z][a-z]{2})(\\d+)_?([A-Z][a-z]{2})?(\\d+)?del$', override=True)\n",
    "# df_tmp = df_tmp.drop(columns=[\"cambio\"])\n",
    "\n",
    "# # # Now process those that have NULL in HGVSP but have some information on \"Mutation AA\"\n",
    "# # # small check in case something is not a missense mutation\n",
    "# check = df_nulls[\"Mutation AA\"].map(lambda x: re.findall('p\\.[A-Z]\\d+\\*$', x))\n",
    "# if np.sum(check.isnull()) > 0:\n",
    "#     print(\"Warning NONSENSE! some nulls or errors here\")\n",
    "\n",
    "# # # continue with mutation processing\n",
    "# df_nulls[\"cambio\"] = df_nulls[\"Mutation AA\"].str.lstrip('p.')\n",
    "# df_done = separar_en_cols_missense(df_nulls, \"cambio\", \"nonsense\", '^([A-Z])(\\d+)(\\*)$', override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deletions[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_en_cols(df, column, conseq, conseq_regex, override=False):\n",
    "    '''\n",
    "    recibe un DataFrame, el nombre de una columna auxiliar (column)\n",
    "    y un string con el tipo de consecuencia (conseq). La col. auxiliar\n",
    "    es una tupla con los elementos implicados en una mutacion\n",
    "    como la siguiente (aa1, start_pos, aa2, end_pos, aa/s_nuevos).\n",
    "    Devuelve el DataFrame df con estas 5 nuevas columnas\n",
    "    '''\n",
    "    \n",
    "    df_crop = df[df[column].str.contains(conseq_regex)].copy()\n",
    "      \n",
    "    if override:\n",
    "        df_crop['aux'] = df_crop[column].str.findall(conseq_regex).str[0]\n",
    "    else:\n",
    "        df_crop['aux'] = df_crop[column].str.findall('^([A-Z][a-z]{2})(\\d+)_?([A-Z][a-z]{2})?(\\d+)?'+conseq_regex+'(.*)$').str[0]\n",
    "        \n",
    "    if conseq == \"missense\" or conseq == \"nonsense\":\n",
    "        df_crop['start_aa'] = df_crop['aux'].map(lambda x: x[1])\n",
    "        df_crop['end_aa'] = df_crop['start_aa']\n",
    "        df_crop['from'] = df_crop['aux'].map(lambda x: x[0])        \n",
    "        df_crop['to'] = df_crop['aux'].map(lambda x: x[2])\n",
    "    else:\n",
    "    \n",
    "        # start position\n",
    "        df_crop['start_aa'] = df_crop['aux'].map(lambda x: x[1])\n",
    "\n",
    "        # end position\n",
    "        df_crop['end_aa'] = df_crop['aux'].map(lambda x: int(x[3]) if x[3] != '' else np.nan)\n",
    "\n",
    "        # from: es el/los aa que cambian\n",
    "        df_crop['from'] = df_crop['aux'].map(lambda x: x[0] + x[2]) # concateno si existe mas de un aa que cambia (o sea, si es un rango)\n",
    "\n",
    "        # to: aa/s nuevos\n",
    "        if conseq == \"nonsense\":\n",
    "            df_crop['to'] = \"Ter\"\n",
    "        elif conseq == \"deletion\":\n",
    "            df_crop['to'] = \"\"\n",
    "        else:\n",
    "            df_crop['to'] = df_crop['aux'].map(lambda x: x[4] if x[4] != '' else np.nan)\n",
    "\n",
    "    # consecuencia de la mutacion\n",
    "    df_crop['consequence'] = conseq\n",
    "\n",
    "    df_crop = df_crop.drop(columns=['aux'])\n",
    "\n",
    "    return df_crop[['cambio', 'start_aa', 'end_aa', 'from', 'to', 'consequence']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conseq_regex = 'del'\n",
    "for e in df_notnulls[ix_right][\"cambio\"]:\n",
    "    m = re.search('^([A-Z][a-z]{2})(\\d+)_?([A-Z][a-z]{2})?(\\d+)?del$', e)\n",
    "    if m is not None:\n",
    "        print(m.group(1), m.group(2), m.group(3), m.group(4))\n",
    "    else:\n",
    "        print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[~ix_nulls][:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[~ix_nulls][\"cambio\"][:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list(df_tmp[~ix_nulls][\"cambio\"].str.findall('^([A-Z][a-z]{2})(\\d+)_?([A-Z][a-z]{2})?(\\d+)?'+conseq_regex+'(.*)$').str[0][0:100])\n",
    "aux = df_notnulls[ix_right][\"cambio\"].str.findall('^([A-Z][a-z]{2})(\\d+)_?([A-Z][a-z]{2})?(\\d+)?del$').str[0][0:100]\n",
    "for x in aux:\n",
    "    print(x[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
